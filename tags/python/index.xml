<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Python on Michele Scipioni</title>
    <link>https://mscipio.github.io/tags/python/</link>
    <description>Recent content in Python on Michele Scipioni</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2017 Michele Scipioni</copyright>
    <lastBuildDate>Tue, 05 Feb 2019 10:26:46 +0100</lastBuildDate>
    
	<atom:link href="https://mscipio.github.io/tags/python/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Calling Matlab (custom) functions from Python</title>
      <link>https://mscipio.github.io/post/matlab-from-python/</link>
      <pubDate>Tue, 05 Feb 2019 10:26:46 +0100</pubDate>
      
      <guid>https://mscipio.github.io/post/matlab-from-python/</guid>
      <description>Nowadays the ability to write codes has become an essential skill in technical and scientific disciplines. Either you like it or not, during your studies you will find yourself doing assignments, solving equations or bigger &amp;lsquo;problems&amp;rsquo; of your projects with some sort of coding. And, if you think of going for higher studies and doing some extensive research, then writing codes is a must know skill for you.
Quite often, students will become familiar with scientific programming (note that I am not specifically refferring to CS students, focused on general purpose coding and programming) through MATLAB.</description>
    </item>
    
    <item>
      <title>Blind Source Separation (BSS) with the Shogun Machine Learning Toolbox</title>
      <link>https://mscipio.github.io/post/bss-shogun-python/</link>
      <pubDate>Sun, 01 May 2016 11:00:00 +0000</pubDate>
      
      <guid>https://mscipio.github.io/post/bss-shogun-python/</guid>
      <description>Strongly inspired by an article by Kevin Hughes (https://github.com/kevinhughes27?tab=repositories) Today I am going to show you how we can do Blind Source Separation (BSS) using algorithms available in the Shogun Machine Learning Toolbox. What is Blind Source Separation? BSS is the separation of a set of source signals from a set of mixed signals.
My favorite example of this problem is known as the cocktail party problem where a number of people are talking simultaneously and we want to separate each persons speech so we can listen to it separately.</description>
    </item>
    
    <item>
      <title>Calculating the posterior probability distribution of parameters with emcee python module</title>
      <link>https://mscipio.github.io/post/posterior-distribution-of-parameter-estimate/</link>
      <pubDate>Sun, 01 May 2016 11:00:00 +0000</pubDate>
      
      <guid>https://mscipio.github.io/post/posterior-distribution-of-parameter-estimate/</guid>
      <description>The emcee() python module emcee can be used to obtain the posterior probability distribution of parameters, given a set of experimental data. An example problem is a double exponential decay. A small amount of Gaussian noise is also added.%matplotlib inline import numpy as np import lmfit from matplotlib import pyplot as plt import corner import emcee from pylab import * ion()  x = np.linspace(1, 10, 250) np.random.seed(0) y = 3.</description>
    </item>
    
    <item>
      <title>Fitting theoretical model to data in python</title>
      <link>https://mscipio.github.io/post/fitting-functions-to-data/</link>
      <pubDate>Sun, 01 May 2016 11:00:00 +0000</pubDate>
      
      <guid>https://mscipio.github.io/post/fitting-functions-to-data/</guid>
      <description>There are several data fitting utilities available. We will focus on two:
 scipy.optimize
 lmfit.minimize
  Using both those modules, you can fit any arbitrary function that you define and it is, also, possible to constrain given parameters during the fit. Another important aspect is that both packages come with useful diagnostic tools.
Fitting Basics The fitting we discuss here is an iterative process.
 First, we define our desired function, and calculate values given certain parameters</description>
    </item>
    
    <item>
      <title>How to read DICOM files into Python</title>
      <link>https://mscipio.github.io/post/read_dicom_files_in_python/</link>
      <pubDate>Sun, 01 May 2016 11:00:00 +0000</pubDate>
      
      <guid>https://mscipio.github.io/post/read_dicom_files_in_python/</guid>
      <description>Dataset Dataset is the main object you will work with directly. Dataset is derived from pythonâ€™s dict, so it inherits (and overrides some of) the methods of dict. In other words it is a collection of key:value pairs, where the key value is the DICOM (group,element) tag (as a Tag object, described below), and the value is a DataElement instance (also described below).
A dataset could be created directly, but you will usually get one by reading an existing DICOM file (it could be a .</description>
    </item>
    
    <item>
      <title>PCA tutorial using scikit-learn python module</title>
      <link>https://mscipio.github.io/post/pca-tutorial-using-scikit-learn-python-module/</link>
      <pubDate>Sun, 01 May 2016 11:00:00 +0000</pubDate>
      
      <guid>https://mscipio.github.io/post/pca-tutorial-using-scikit-learn-python-module/</guid>
      <description>Dimensionality Reduction: Principal Component Analysis in-depth Here we&amp;rsquo;ll explore Principal Component Analysis, which is an extremely useful linear dimensionality reduction technique.
We&amp;rsquo;ll start with our standard set of initial imports:from __future__ import print_function, division %matplotlib inline import numpy as np import matplotlib.pyplot as plt from scipy import stats # use seaborn plotting style defaults import seaborn as sns; sns.set()  Introducing Principal Component Analysis Principal Component Analysis is a very powerful unsupervised method for dimensionality reduction in data.</description>
    </item>
    
    <item>
      <title>Simple nonlinear least squares curve fitting in Python</title>
      <link>https://mscipio.github.io/post/python_nonlinear_least_squares/</link>
      <pubDate>Sun, 01 May 2016 11:00:00 +0000</pubDate>
      
      <guid>https://mscipio.github.io/post/python_nonlinear_least_squares/</guid>
      <description>The problem Today we are going to test a very simple example of nonlinear least squares curve fitting using the scipy.optimize module.
%matplotlib inline import numpy as np import matplotlib.pyplot as plt from scipy.optimize import curve_fit  Create data Let&amp;rsquo;s assume we have the following points [xdata, ydata] and that we want to fit these data with the following model function using nonlinear least squares:
$F(p_1,p_2,x) = p_1\cos(p_2x) + p_2\sin(p_1x)$</description>
    </item>
    
  </channel>
</rss>
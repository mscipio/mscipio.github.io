<!DOCTYPE html>
<html lang="en-us">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="theme" content="hugo-academic">
  <meta name="generator" content="Hugo 0.54.0" />
  <meta name="author" content="Michele Scipioni">
  <meta name="description" content="Ph.D. student in Biomedical Engineering">

  
  
  
    
  
  
    
    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/styles/github.min.css">
    
  
  
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/css/bootstrap.min.css" integrity="sha512-6MXa8B6uaO18Hid6blRMetEIoPqHf7Ux1tnyIQdpt9qI5OACx7C+O3IVTr98vwGnlcg0LOLa02i9Y1HpVhlfiw==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.0/css/academicons.min.css" integrity="sha512-GGGNUPDhnG8LEAEDsjqYIQns+Gu8RBs4j5XGlxl7UfRaZBhCCm5jenJkeJL8uPuOXGqgl8/H1gjlWQDRjd3cUQ==" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" integrity="sha512-SfTiTlX6kk+qitfevl/7LibUOeJWlt9rbyDn92a1DqWOw9vWG2MFoays0sgObmWazO5BQPiFucnnEAjpAB+/Sw==" crossorigin="anonymous">
  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Lato:400,700%7CMerriweather%7CRoboto+Mono">
  <link rel="stylesheet" href="/css/hugo-academic.css">
  

  

  <link rel="alternate" href="https://mscipio.github.io/index.xml" type="application/rss+xml" title="Michele Scipioni">
  <link rel="feed" href="https://mscipio.github.io/index.xml" type="application/rss+xml" title="Michele Scipioni">

  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/apple-touch-icon.png">

  <link rel="canonical" href="https://mscipio.github.io/post/pca-tutorial-using-scikit-learn-python-module/">

  <link rel="stylesheet" href="https://mscipio.github.io/css/override.css">


  <title>PCA tutorial using scikit-learn python module | Michele Scipioni</title>

</head>
<body id="top" data-spy="scroll" data-target="#navbar-main" data-offset="71">

<nav class="navbar navbar-default navbar-fixed-top" id="navbar-main">
  <div class="container">

    
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse"
              data-target=".navbar-collapse" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="/">Michele Scipioni</a>
    </div>

    
    <div class="collapse navbar-collapse">

      
      <ul class="nav navbar-nav navbar-right">
        

        

        <li class="nav-item">
          <a href="/#about">
            
            <span>Home</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#posts">
            
            <span>Posts</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#publications">
            
            <span>Publications</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#projects">
            
            <span>Projects</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#teaching">
            
            <span>Teaching</span>
          </a>
        </li>

        
        

        

        <li class="nav-item">
          <a href="/#contact">
            
            <span>Contact</span>
          </a>
        </li>

        
        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  
<div class="article-header">
  
  <h1 itemprop="name">PCA tutorial using scikit-learn python module</h1>
</div>  



  <div class="article-container">
    
    

<div class="article-metadata">

  <span class="article-date">
    <time datetime="2016-05-01 11:00:00 &#43;0000 UTC" itemprop="datePublished">
      Sun, May 1, 2016
    </time>
  </span>

  

  
  
  
  <span class="article-tags">
    <i class="fa fa-tags"></i>
    
    <a href="/tags/pca">PCA</a
    >, 
    
    <a href="/tags/python">python</a
    >, 
    
    <a href="/tags/scikit-learn">scikit-learn</a
    >
    
  </span>
  
  

  
  
<div class="share-box" aria-hidden="true">
  <ul class="share">
    <li>
      <a class="facebook"
         href="https://www.facebook.com/sharer.php?u=https%3a%2f%2fmscipio.github.io%2fpost%2fpca-tutorial-using-scikit-learn-python-module%2f"
         target="_blank">
        <i class="fa fa-facebook"></i>
      </a>
    </li>
    <li>
      <a class="twitter"
         href="https://twitter.com/intent/tweet?text=PCA%20tutorial%20using%20scikit-learn%20python%20module&amp;url=https%3a%2f%2fmscipio.github.io%2fpost%2fpca-tutorial-using-scikit-learn-python-module%2f"
         target="_blank">
        <i class="fa fa-twitter"></i>
      </a>
    </li>
    <li>
      <a class="linkedin"
         href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fmscipio.github.io%2fpost%2fpca-tutorial-using-scikit-learn-python-module%2f&amp;title=PCA%20tutorial%20using%20scikit-learn%20python%20module"
         target="_blank">
        <i class="fa fa-linkedin"></i>
      </a>
    </li>
    <li>
      <a class="weibo"
         href="http://service.weibo.com/share/share.php?url=https%3a%2f%2fmscipio.github.io%2fpost%2fpca-tutorial-using-scikit-learn-python-module%2f&amp;title=PCA%20tutorial%20using%20scikit-learn%20python%20module"
         target="_blank">
        <i class="fa fa-weibo"></i>
      </a>
    </li>
    <li>
      <a class="email"
         href="mailto:?subject=PCA%20tutorial%20using%20scikit-learn%20python%20module&amp;body=https%3a%2f%2fmscipio.github.io%2fpost%2fpca-tutorial-using-scikit-learn-python-module%2f">
        <i class="fa fa-envelope"></i>
      </a>
    </li>
  </ul>
</div>


  

</div>

    <div class="article-style" itemprop="articleBody">
      

<h2 id="dimensionality-reduction-principal-component-analysis-in-depth">Dimensionality Reduction: Principal Component Analysis in-depth</h2>

<p>Here we&rsquo;ll explore Principal Component Analysis, which is an extremely useful linear dimensionality reduction technique.</p>

<p>We&rsquo;ll start with our standard set of initial imports:<!-- TEASER_END --></p>

<pre><code class="language-python">from __future__ import print_function, division

%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
from scipy import stats

# use seaborn plotting style defaults
import seaborn as sns; sns.set()
</code></pre>

<h2 id="introducing-principal-component-analysis">Introducing Principal Component Analysis</h2>

<p>Principal Component Analysis is a very powerful unsupervised method for dimensionality reduction in data. It&rsquo;s easiest to visualize by looking at a two-dimensional dataset:</p>

<pre><code class="language-python">np.random.seed(1)
X = np.dot(np.random.random(size=(2, 2)), np.random.normal(size=(2, 200))).T
plt.plot(X[:, 0], X[:, 1], 'o')
plt.axis('equal')
print(X.shape)
</code></pre>

<pre><code>(200, 2)
</code></pre>

<p><img src="../../img/posts/pca-tutorial-using-scikit-learn-python-module/output_4_1.png" alt="png" /></p>

<p>We can see that there is a definite trend in the data. What PCA seeks to do is to find the Principal Axes in the data, and explain how important those axes are in describing the data distribution:</p>

<pre><code class="language-python">from sklearn.decomposition import PCA
pca = PCA(n_components=2)
pca.fit(X)
print(pca.explained_variance_)
print(pca.components_)
</code></pre>

<pre><code>[ 0.75871884  0.01838551]
[[ 0.94446029  0.32862557]
 [ 0.32862557 -0.94446029]]
</code></pre>

<p>To see what these numbers mean, let&rsquo;s view them as vectors plotted on top of the data:</p>

<pre><code class="language-python">plt.plot(X[:, 0], X[:, 1], 'o', alpha=0.5)
for length, vector in zip(pca.explained_variance_, pca.components_):
    v = vector * 3 * np.sqrt(length)
    plt.plot([0, v[0]], [0, v[1]], '-k', lw=3)
plt.axis('equal');
</code></pre>

<p><img src="output_8_0.png" alt="png" /></p>

<p>Notice that one vector is longer than the other. In a sense, this tells us that that direction in the data is somehow more &ldquo;important&rdquo; than the other direction. The explained variance quantifies this measure of &ldquo;importance&rdquo; in direction.</p>

<p>Another way to think of it is that the second principal component could be completely ignored without much loss of information! Let&rsquo;s see what our data look like if we only keep 95% of the variance:</p>

<pre><code class="language-python">clf = PCA(0.95) # keep 95% of variance
X_trans = clf.fit_transform(X)
print(X.shape)
print(X_trans.shape)
</code></pre>

<pre><code>(200, 2)
(200, 1)
</code></pre>

<p>By specifying that we want to throw away 5% of the variance, the data is now compressed by a factor of 50%! Let&rsquo;s see what the data look like after this compression:</p>

<pre><code class="language-python">X_new = clf.inverse_transform(X_trans)
x_plot = plt.plot(X[:, 0], X[:, 1], 'o', alpha=0.4, label='X')
xnew_plot = plt.plot(X_new[:, 0], X_new[:, 1], 'ob', alpha=0.8, label='X_new')
plt.axis('equal')
plt.legend()
</code></pre>

<pre><code>&lt;matplotlib.legend.Legend at 0x7ff9f16f7f50&gt;
</code></pre>

<p><img src="../../img/posts/pca-tutorial-using-scikit-learn-python-module/output_12_1.png" alt="png" /></p>

<p>The light points are the original data, while the dark points are the projected version. We see that after truncating 5% of the variance of this dataset and then reprojecting it, the &ldquo;most important&rdquo; features of the data are maintained, and we&rsquo;ve compressed the data by 50%!</p>

<p>This is the sense in which &ldquo;dimensionality reduction&rdquo; works: if you can approximate a data set in a lower dimension, you can often have an easier time visualizing it or fitting complicated models to the data.</p>

<h2 id="what-do-the-components-mean">What do the Components Mean?</h2>

<p>PCA is a very useful dimensionality reduction algorithm, because it has a very intuitive interpretation via eigenvectors. The input data is represented as a vector: If we reduce the dimensionality in the pixel space to (say) 6, we recover only a partial image.</p>

<pre><code class="language-python">from sklearn.datasets import load_digits
digits = load_digits()
X = digits.data
y = digits.target
</code></pre>

<p>What PCA does is to choose optimal basis functions so that only a few are needed to get a reasonable approximation. The low-dimensional representation of our data is the coefficients of this series, and the approximate reconstruction is the result of the sum:</p>

<h3 id="choosing-the-number-of-components">Choosing the Number of Components</h3>

<p>But how much information have we thrown away? We can figure this out by looking at the explained variance as a function of the components:</p>

<pre><code class="language-python">sns.set()
pca = PCA().fit(X)
plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance');
</code></pre>

<p><img src="../../img/posts/pca-tutorial-using-scikit-learn-python-module/output_18_0.png" alt="png" /></p>

<p>Here we see that our two-dimensional projection loses a lot of information (as measured by the explained variance) and that we&rsquo;d need about 20 components to retain 90% of the variance. Looking at this plot for a high-dimensional dataset can help you understand the level of redundancy present in multiple observations.</p>

    </div>
  </div>

</article>

<div class="article-container"></div>

<script src="https://utteranc.es/client.js"
  repo="mscipio/mscipio.github.io"
  issue-term="pathname"
  label="Comment"
  theme="github-light"
  crossorigin="anonymous"
  async>
</script>

</div>

<div class="container">
    <nav>
  <ul class="pager">
    
    <li class="previous"><a href="https://mscipio.github.io/post/python_nonlinear_least_squares/"><span
      aria-hidden="true">&larr;</span> Simple nonlinear least squares curve fitting in Python</a></li>
    

    
    <li class="next"><a href="https://mscipio.github.io/post/read_dicom_files_in_python/">How to read DICOM files into Python <span
      aria-hidden="true">&rarr;</span></a></li>
    
  </ul>
</nav>

</div>

<footer class="site-footer">
  <div class="container">
    <p class="powered-by">

      &copy; 2017 Michele Scipioni &middot; 

      Powered by the <a href="https://github.com/gcushen/hugo-academic" target="_blank">Academic
      theme</a> for <a href="http://gohugo.io" target="_blank">Hugo</a>.

      <span class="pull-right" aria-hidden="true">
        <a href="#" id="back_to_top">
          <span class="button_icon">
            <i class="fa fa-chevron-up fa-2x"></i>
          </span>
        </a>
      </span>

    </p>
  </div>
</footer>

    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.12.4/jquery.min.js" integrity="sha512-jGsMH83oKe9asCpkOVkBnUrDDTp8wl+adkB2D+//JtlxO4SrLoJdhbOysIFQJloQFD+C4Fl1rMsQZF76JjV0eQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.2/imagesloaded.pkgd.min.js" integrity="sha512-iHzEu7GbSc705hE2skyH6/AlTpOfBmkx7nUqTLGzPYR+C1tRaItbRlJ7hT/D3YQ9SV0fqLKzp4XY9wKulTBGTw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/TweenMax.min.js" integrity="sha512-Z5heTz36xTemt1TbtbfXtTq5lMfYnOkXM2/eWcTTiLU01+Sw4ku1i7vScDc8fWhrP2abz9GQzgKH5NGBLoYlAw==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/gsap/1.19.1/plugins/ScrollToPlugin.min.js" integrity="sha512-CDeU7pRtkPX6XJtF/gcFWlEwyaX7mcAp5sO3VIu/ylsdR74wEw4wmBpD5yYTrmMAiAboi9thyBUr1vXRPA7t0Q==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha512-iztkobsvnjKfAtTNdHkGVjAYTrrtlC7mGp/54c40wowO7LhURYl3gVzzcEqGl/qKXQltJ2HwMrdLcNUdo+N/RQ==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
    
    <script src="/js/hugo-academic.js"></script>
    

    
    
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/highlight.min.js"></script>

      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/languages/python.min.js"></script>
      
      <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.9.0/languages/matlab.min.js"></script>
      

      

      <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({ tex2jax: { inlineMath: [['$','$'], ['\\(','\\)']] } });
    </script>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS_CHTML" integrity="sha512-tOav5w1OjvsSJzePRtt2uQPFwBoHt1VZcUq8l8nm5284LEKE9FSJBQryzMBzHxY5P0zRdNqEcpLIRVYFNgu1jw==" crossorigin="anonymous"></script>
    
    

  </body>
</html>

